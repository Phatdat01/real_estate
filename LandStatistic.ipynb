{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from image_downloading import  run, image_size\n",
    "from geo_func import split_polygon, read_geopandas_data\n",
    "import time\n",
    "from shapely.geometry import Point, Polygon\n",
    "from matplotlib.path import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing ward of Dalat city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ward = \"12\"\n",
    "geo = read_geopandas_data(ward=\"12\")\n",
    "G = np.random.choice(geo.geometry.values)\n",
    "\n",
    "squares = split_polygon(G, shape='square', thresh=0, side_length=0.005)\n",
    "geo_series = gpd.GeoSeries(squares)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Render mask process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this index is specified for ward 12\n",
    "tf_lon, _, _, tf_lat = geo_series[56].bounds #this is top-left square\n",
    "_, br_lat, br_lon, _ = geo_series[0].bounds #this is bottom-right square\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "W, H = image_size(tf_lat, tf_lon, br_lat, br_lon, zoom=19)\n",
    "W = geo_series[0].shape[0]*(W//geo_series[0].shape[0])\n",
    "H = geo_series[0].shape[1]*(H//geo_series[0].shape[1])\n",
    "print(W,H)\n",
    "dx = (br_lon-tf_lon)/W\n",
    "dy = (tf_lat-br_lat)/H\n",
    "\n",
    "valuesx = np.arange(0, W)\n",
    "oney = np.ones((1,H), dtype=int)\n",
    "image_dx = valuesx.reshape((W,1))*oney\n",
    "\n",
    "valuesy = np.arange(H,0, -1)\n",
    "onex = np.ones((W,1), dtype=int)\n",
    "image_dy = valuesy.reshape((1,H))*onex\n",
    "\n",
    "lon = np.add(image_dx*dx, tf_lon)\n",
    "lat = np.add(image_dy*dy, br_lat)\n",
    "\n",
    "area = {}\n",
    "boundary = Polygon(read_geopandas_data()[5485])\n",
    "\n",
    "path = Path(list(boundary.exterior.coords))  # Create Path from Polygon's vertices\n",
    "\n",
    "\n",
    "def is_point_inside_polygon(point):\n",
    "    return path.contains_point(point)\n",
    "\n",
    "mask = np.full(lat.shape, False, dtype=bool)\n",
    "# Check if point is inside the polygon\n",
    "#mask = np.array([[is_point_inside_polygon((lon[i][j], lat[i][j])) for j in range(W)] for i in range(H)], dtype=bool)\n",
    "print(lon.shape, lat.shape)\n",
    "for i in range(W):\n",
    "    if(i%500 == 0):\n",
    "        print(time.time()-start)\n",
    "    for j in range(H):\n",
    "        mask[i,j] = is_point_inside_polygon((lon[i][j], lat[i][j]))\n",
    "\n",
    "np.save(\"mask_\"+ward, mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference model result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from mmengine.model.utils import revert_sync_batchnorm\n",
    "from mmseg.apis import init_model, inference_model, show_result_pyplot\n",
    "config_file = './configs/segformer/segformer_mit-b5_8xb2-160k_loveda-640x640.py'\n",
    "checkpoint_file = '/mmsegmentation/data/segformer.pth'\n",
    "# build the model from a config file and a checkpoint file\n",
    "model = init_model(config_file, checkpoint_file, device='cuda')\n",
    "\n",
    "import os\n",
    "if not torch.cuda.is_available():\n",
    "    model = revert_sync_batchnorm(model)\n",
    "folder_path = '/mmsegmentation/data/test/images_raw'\n",
    "for filename in os.listdir(folder_path):\n",
    "        image_path = os.path.join(folder_path, filename)\n",
    "\n",
    "        result = inference_model(model, image_path)\n",
    "        vis_iamge = show_result_pyplot(model, image_path, result, save_dir ='data/results/',\n",
    "                                    opacity=1.0, show=False,  draw_gt=True, with_labels=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rendering Land statistic result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### render report function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_area(image, mask):\n",
    "    \"\"\"\n",
    "    Calculates the area for each unique value in the image within the mask.\n",
    "\n",
    "    Args:\n",
    "        image (numpy.ndarray): The image where the values are counted.\n",
    "        mask (numpy.ndarray): The mask defining the area of interest.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary with unique values as keys and the corresponding area as values.\n",
    "    \"\"\"\n",
    "    # Count the unique values in the image within the mask\n",
    "    unique_values, counts = np.unique(image[mask], return_counts=True)\n",
    "\n",
    "    # Calculate the area for each unique value\n",
    "    area = {}\n",
    "    for i in range(len(unique_values)):\n",
    "        # Calculate the area for each unique value\n",
    "        # The area is calculated as counts * pixel size (0.2986m) squared / 1000000\n",
    "        area[unique_values[i]] = (counts[i] * 0.2986 * 0.2986) / 1000000\n",
    "\n",
    "    return area\n",
    "def merging_row(index, folder_path):\n",
    "    \"\"\"\n",
    "    Merges images from different rows into a single row image.\n",
    "\n",
    "    Args:\n",
    "        index (list): List of indexes of the images to be merged.\n",
    "        folder_path (str): Path to the folder containing the images.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Merged image with dimensions (height, width*len(index)).\n",
    "    \"\"\"\n",
    "    # Define the color ranges for each label\n",
    "    color_ranges = {       \n",
    "        0: [255, 255, 255],  # White\n",
    "        1: [0,0,255],  # Blue\n",
    "        2: [0,255,255],  # Cyan\n",
    "        3: [255,0,0],  # Red\n",
    "        4: [183, 129, 159],  # Pink\n",
    "        5: [0,255,0],  # Green\n",
    "        6: [128, 195, 255],  # Light blue\n",
    "    }\n",
    "    \n",
    "    # Read the first image, encode it to 1D array, and initialize the merged image\n",
    "    image_row = cv2.imread(os.path.join(folder_path, str(index[0])+\".png\"))\n",
    "    image_row = encode_image_to_1d(image_row, color_ranges)\n",
    "    merged_image = image_row\n",
    "\n",
    "    # Merge the remaining images\n",
    "    for i in index[1:]:\n",
    "        image_path = os.path.join(folder_path, str(i)+\".png\")\n",
    "        image = cv2.imread(image_path)\n",
    "        image = encode_image_to_1d(image, color_ranges)\n",
    "        merged_image = np.concatenate((merged_image, image), axis=1)\n",
    "\n",
    "    return merged_image\n",
    "def encode_image_to_1d(image, color_ranges):\n",
    "  \"\"\"\n",
    "  Encodes an image with specified color ranges to a 1D array with label values (0-6).\n",
    "\n",
    "  Args:\n",
    "      image: A 3D NumPy array representing the image (height, width, channels).\n",
    "      color_ranges: A dictionary mapping label names to tuples of color ranges (BGR).\n",
    "\n",
    "  Returns:\n",
    "      A 1D NumPy array containing label values (0-6) for each pixel in the image.\n",
    "  \"\"\"\n",
    "\n",
    "  # Create an empty encoded image to store label values (0 to 6)\n",
    "  img_classes = np.zeros_like(image)[:, :, 0]  # Initialize with first channel\n",
    "  unique_colors = set()\n",
    "  for label, rgb in color_ranges.items():\n",
    "    img_classes[(image==rgb).all(axis=2)] = label\n",
    "    unique_values, counts = np.unique(img_classes, return_counts=True)\n",
    "    \n",
    "  unique_values, counts = np.unique(img_classes, return_counts=True)\n",
    "  print(unique_values, counts)\n",
    "\n",
    "  return img_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"data/results/\" #Model results directory\n",
    "\n",
    "#This index is specified for ward 12\n",
    "index1=[i for i in range(56,64)]\n",
    "index2=[i for i in range(48,56)]\n",
    "index3=[i for i in range(40,48)]\n",
    "index4=[i for i in range(32,40)]\n",
    "index5=[i for i in range(24,32)]\n",
    "index6=[i for i in range(16,24)]\n",
    "index7=[i for i in range(8,16)]\n",
    "index8 = np.arange(7, -1, -1)\n",
    "index = [index1, index2, index3, index4, index5, index6, index7, index8]\n",
    "big_images=merging_row(index[0], folder_path=folder_path)\n",
    "for i in index[1:]:\n",
    "    image=merging_row(i, folder_path=folder_path)\n",
    "    big_images = np.concatenate((big_images, image))\n",
    "    \n",
    "print(big_images.shape)\n",
    "area = (calculate_area(big_images, mask)) \n",
    "\n",
    "unique_values, counts = np.unique(mask, return_counts=True)\n",
    "print(unique_values, counts)\n",
    "\n",
    "total_sum = sum(area.values())\n",
    "print(total_sum)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
